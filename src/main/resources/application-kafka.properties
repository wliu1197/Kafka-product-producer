spring.application.name=productsMicroservice
server.port=8080
spring.kafka.producer.bootstrap-servers=localhost:9092,localhost:9094
spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
spring.kafka.producer.value-serializer=org.springframework.kafka.support.serializer.JsonSerializer

#producer will wait for all broker servers to return acknowledgements back
#spring.kafka.producer.acks=all
#spring.kafka.producer.acks=1 (only wait for leader broker to send acks back)
# for idempotence to work this must be all
spring.kafka.producer.acks=all

# by defualt is max integer value and in order for idempotence to work you need to have this >0
#when message failed to be stored in kafka broker it will retry max 10 times
spring.kafka.producer.retries=10

#wait time between each retry
spring.kafka.producer.properties.retry.backoff.ms=1000

#producer wait 2 mins(default is 2 mins) for acks then time out
#aws api-gateway has 39 seconde limite so if we use AWS this should be 29s
#otherwise even the message stored we won't get acks as api timeout already
spring.kafka.producer.properties.delivery.timeout.ms=29000
#delivery.timeout.ms>=linger.ms+request.timeout.ms
#producer wait 0 ms for buffer data before sending message to broker (by default is 0ms)
spring.kafka.producer.properties.linger.ms=0
#producer wait for each ack response (by defualt is 30000ms)
spring.kafka.producer.properties.request.timeout.ms=29000

# By setting your producer as idempotence
# To avoid duplicate messages stored in broker partitions
# when acknowledge send back to producer if producer has network issue didn't receive ack
# it will retry to send again same message in this time the same message won't be stored
# broker will return ack again directly
# this by default is enabled
spring.kafka.producer.properties.enable.idempotence=true
# how many requests can be made in parallel to any partition
# by defualt is 5 and in order for idempotence to work you need to have this <=5
spring.kafka.producer.properties.max.in.flight.request.per.connection=5
#This mapping is for serialization and deserialization format in token:className
#When producer send message it would use same token name map with producer's className for serialization
#When consumer consume message it would use same token name map with consumer's className for deserialization
#spring.kafka.producer.properties.spring.json.type.mapping=productcreatedevent:com.kafka.ms.products.model.event.ProductCreatedEvent


# apply kafka transaction
# enable Kafka transaction when produce messages to topics
# if we are running microservice in AWS ECS we have multiple instances then for each instance it needs unique transaction-id-prefix
# ${random.value} will generate unique value in the transaction-id-prefix and Kafka will auto append id after prefix for each transaction
# e.g: transfer-service-${random.value}-0, transfer-service-${random.value}-1 etc...
spring.kafka.producer.transaction-id-prefix=transfer-service-${random.value}-
logging.level.org.springframework.kafka.transaction=TRACE
logging.level.org.springframework.transaction=TRACE